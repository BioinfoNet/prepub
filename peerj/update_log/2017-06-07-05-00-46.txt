[u'Integrating active learning and crowdsourcing into large-scale supervised landcover mapping algorithms', ['Stephanie R Debats', 'Lyndon D Estes', 'David R Thompson', 'Kelly K Caylor'], u'2017-06-06', u'Sub-Saharan Africa and other developing regions of the world are dominated by smallholder farms, which are characterized by small, heterogeneous, and often indistinct field patterns. In previous work, we developed an algorithm for mapping both smallholder and commercial agricultural fields that includes efficient extraction of a vast set of simple, highly correlated, and interdependent features, followed by a random forest classifier. In this paper, we demonstrated how active learning can be incorporated in the algorithm to create smaller, more efficient training data sets, which reduced computational resources, minimized the need for humans to hand-label data, and boosted performance. We designed a patch-based uncertainty metric to drive the active learning framework, based on the regular grid of a crowdsourcing platform, and demonstrated how subject matter experts can be replaced with fleets of crowdsourcing workers. Our active learning algorithm achieved similar performance as an algorithm trained with randomly selected data, but with 62% less data samples.', u'https://peerj.com/preprints/3004/', ['Human-Computer Interaction', 'Algorithms and Analysis of Algorithms', 'Computer Vision', 'Spatial and Geographic Information Systems'], [u'Department of Civil & Environmental Engineering, Princeton University', u'NASA Jet Propulsion Laboratory', u'Department of Geography, University of California, Santa Barbara', u'Bren School of Environmental Science and Management, University of California, Santa Barbara']]
[u'A possible linear filtering model to explain White\u2019s illusion at different grating widths', ['Soma Mitra', 'Deabasis Mazumdar', 'Kuntal Ghosh', 'Kamales Bhaumik'], u'2017-06-06', u'The perceived lightness of a stimulus depends on its background, a phenomenon known as lightness induction. For instance, the same gray stimulus can look light in one background and dark in another. Moreover, such induction can take place in two directions; in one case, it occurs in the direction of the background lightness known as lightness assimilation, while in the other it occurs opposite to that, known as lightness contrast. The White\u2019s illusion is a typical one which does not completely conform to any of these two processes. In this paper, we have quantified the perceptual strength of the White\u2019s illusion as a function of the width of the background square grating. Based on our results which also corroborate some earlier studies, we propose a linear filtering model inspired from an earlier work dealing with varying Mach band widths. Our model assumes that the for the White\u2019s illusion, where the edges are strong and many in number, and as such the spectrum is rich in high frequency components, the inhibitory surround in the classical Difference-of-Gaussians (DoG) filter gets suppressed, so that the filter essentially reduces to a multi-scale Gaussian one. The simulation results with this model support the present as well as earlier experimental results.', u'https://peerj.com/preprints/3009/', ['Neuroscience'], [u'Center for Development of Advanced Computing', u'Indian Statistical Institute']]
[u'Evaluation of the maxillary anterior teeth color distribution according to age and gender with Spectrophotometer', ['Tahir Karaman', 'Eyyup Altintas', 'Bekir Eser', 'Tuba Talo Yildirim', 'Faruk Oztekin', 'Alihan Bozoglan'], u'2017-06-06', u'Background: This study intended to determine the colour distribution of the maxillary, central, lateral and canine teeth and to investigate the effect of age and gender on this colour distribution.\nMaterials and methods : The colour measurements of the maxillary right central, lateral and canine teeth were carried out by the Vita Easyshade V (Vita Zahnfabrik, Bad Sackingen, Germany) spectrophotometer on a total of 202 voluntarily patients including 89 (men) and 113 (women). The age distribution in the study was between 15 and 70 (the average was 31). Grey background colour was used in order to prevent the reflection of the background while performing the colour measurement with the Vita EasyShade V (Vita Zahnfabrik, Bad Sackingen, Germay).\nResults: When comparing the L*, a* and b* values of the teeth with the gender; statistically significant difference was not fount between the gender and the L* and b* values (P>0,05) while statistically significant difference was observed between the gender and the a* value (P<0,05).\nConclusions: The tooth colour distribution according to the Vitapan Classical; in the central and lateral teeth it was maximum A2, while it was found to be B3 in the canine teeth. The tooth colour distribution according to the VITA Toothguide 3D-MASTER colour scale; in the central teeth the 2M2 colour was measured most often, in the lateral teeth the 3M2 colour was detected the most often while in the canine teeth the 2M3 colour was measured the most often.', u'https://peerj.com/preprints/3008/', ['Dentistry'], [u'Department of Prosthodontics, Faculty of Dentistry, F\u0131rat University', u'Department of Periodontology, Faculty of Dentistry, F\u0131rat University', u'Department of Endodontics, Faculty of Dentistry, F\u0131rat University']]
[u'Multi-label classification of frog species via deep learning', ['Jie Xie'], u'2017-06-06', u'Acoustic classification of frogs has received increasing attention for its promising application in ecological studies. Various studies have been proposed for classifying frog species, but most recordings are assumed to have only a single species. In this study, a method to classify multiple frog species in an audio clip is presented. To be specific, continuous frog recordings are first cropped into audio clips (10 seconds). Then, various time-frequency representations are generated for each 10-s recording. Next, instead of using traditional hand-crafted features, a deep learning algorithm is used to find the most important feature. Finally, a binary relevance based multi-label classification approach is proposed to classify simultaneously vocalizing frog species with our proposed features. Experimental results show that our proposed features extracted using deep learning can achieve better classification performance when compared to hand-crafted features for frog call classification.', u'https://peerj.com/preprints/3007/', ['Artificial Intelligence', 'Data Mining and Machine Learning', 'Multimedia'], [u'\u200bDepartment of Electrical and Computer Engineering, University of Waterloo']]
