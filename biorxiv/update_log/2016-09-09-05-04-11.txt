[u'Learning to cooperate: The evolution of social rewards in repeated interactions', ['Slimane Dridi', 'Erol Akcay'], u'September 8, 2016.', u"Understanding the behavioral and psychological mechanisms underlying social behaviors is one of the major outstanding goals of social evolutionary theory. In particular, a persistent question about human--and animal--cooperation is to what extent it is supported by other-regarding preferences--the motivation to increase the welfare of others. In real-world situations, individuals have the opportunity to learn from past interactions, so we may ask how individuals evolve to learn to satisfy their social preferences during the course of an interaction. In this context, the rewards an individual receives from his social behaviors capture his preferences. In this paper, we develop a mathematical model in order to ask whether the mere act of cooperating with a social partner will evolve to be inherently rewarding. In our model, individuals interact repeatedly in pairs and adjust their behaviors through reinforcement learning. Individuals associate to each game outcome a subjective utility, which constitute the reward for that particular outcome. We find that utilities that value mutual cooperation positively but the sucker's outcome negatively are evolutionarily stable. In a reduced model, other-regarding preferences can co-exist with preferences that match the sign of the material payoffs under narrow conditions. In simulations of the full model, we find that selfish preferences that always learn pure defection are also evolutionarily successful. These findings are consistent with empirical observations showing that humans tend to behave according to distinct behavioral types, and call for further integration of different levels of biological and social determinants of behavior.", u'/content/early/2016/09/08/074096', [], [u'University of Pennsylvania']]
[u'Phylogenetic factorization of compositional data', ['Alex D Washburne', 'Justin D Silverman', 'Jonathan Leff', 'Dominic J Bennett', 'John L Darcy', 'Sayan Mukherjee', 'Noah Fierer', 'Lawrence A David'], u'September 8, 2016.', u'Marker gene sequencing of microbial communities has generated big datasets of microbial relative abundances varying across environmental conditions, sample sites and treatments. These data often come with putative phylogenies, providing unique opportunities to investigate how shared evolutionary history affects microbial abundance patterns. Here, we present a method to identify the phylogenetic factors driving patterns in microbial community composition. We use the method, "phylofactorization", to re-analyze datasets from human body and soil microbial communities, demonstrating how phylofactorization can be a dimensionality-reducing tool, an ordination-visualization tool, and also mass-produce inferences on the edges in the phylogeny in which meaningful differences arose.', u'/content/early/2016/09/08/074112', [], [u'Duke University, Nicholas School of the Environment;', u'Duke University;', u'UC Boulder;', u'Imperial College London']]
[u'Power Analysis of Single Cell RNA\u2010Sequencing Experiments', ['Valentine Svensson', 'Kedar N Natarajan', 'Lam-Ha Ly', 'Ricardo J Miragaia', 'Charlotte Labalette', 'Iain C Macaulay', 'Ana Cvejic', 'Sarah A Teichmann'], u'September 8, 2016.', u'High-throughput single cell RNA sequencing (scRNA-seq) has become an established and powerful method to investigate transcriptomic cell-to-cell variation, and has revealed new cell types, and new insights into developmental process and stochasticity in gene expression. There are now several published scRNA-seq protocols, which all sequence transcriptomes from a minute amount of starting material. Therefore, a key question is how these methods compare in terms of sensitivity of detection of mRNA molecules, and accuracy of quantification of gene expression. Here, we assessed the sensitivity and accuracy of  many  published data sets based on standardized spike-ins  with a uniform raw data processing pipeline. We developed a flexible and fast UMI counting tool (https://github.com/vals/umis) which is compatible with all UMI based\nprotocols.  This allowed us to relate these parameters to sequencing depth, and discuss the trade offs between the different methods.  To confirm our results, we performed experiments on cells from the same population using three different protocols. We also investigated the effect of RNA degradation on spike-in molecules, and the average efficiency of scRNA-seq on spike-in molecules  versus endogenous RNAs.', u'/content/early/2016/09/08/073692', [], [u'EMBL-EBI;', u'Wellcome Trust Sanger Institute']]
[u'Improving genetic diagnosis in Mendelian disease with transcriptome sequencing', ['Beryl B Cummings', 'Jamie Lind Marshall', 'Taru Tukiainen', 'Monkol Lek', 'Sandra Donkervoort', 'Aileen Reghan Foley', 'Veronique Bolduc', 'Leigh Brook Waddell', 'Sarah Annabella Sandaradura', "Gina L O'Grady", 'Elicia Estrella', 'Hemakumar Mutra Reddy', 'Fengmei Zhao', 'Ben Weisburd', 'Konrad Karczewski', "Anne O'Donnell-Luria", 'Daniel Birnbaum', 'Anna Sarkozy', 'Ying Hu', 'Hernan Gonorazky', 'Kristl Claeys', 'Himanshu Joshi', 'Adam Bournazos', 'Emily Oates', 'Roula Ghaoui', 'Mark Davis', 'Nigel G Laing', 'Ana Topf', 'GTEx Consortium', 'Alan Beggs', 'Peter B Kang', 'Kathryn N North', 'Volker Straub', 'James Dowling', 'Francesco Muntoni', 'Nigel F Clarke', 'Sandra T Cooper', 'Carsten G Bonnemann', 'Daniel Geoffrey MacArthur'], u'September 8, 2016.', u'Exome and whole-genome sequencing are becoming increasingly routine approaches in Mendelian disease diagnosis. Despite their success, the current diagnostic rate for genomic analyses across a variety of rare diseases is approximately 25-50% [1-4]. Here, we explore the utility of transcriptome sequencing (RNA-seq) as a complementary diagnostic tool in a cohort of 50 patients with genetically undiagnosed rare neuromuscular disorders. We describe an integrated approach to analyze patient muscle RNA-seq, leveraging an analysis framework focused on the detection of transcript-level changes that are unique to the patient compared to over 180 control skeletal muscle samples. We demonstrate the power of RNA-seq to validate candidate splice-disrupting mutations and to identify splice-altering variants in both exonic and deep intronic regions, yielding an overall diagnosis rate of 35%. We also report the discovery of a highly recurrent de novo intronic mutation in COL6A1 that results in a dominantly acting splice-gain event, disrupting the critical glycine repeat motif of the triple helical domain. We identify this pathogenic variant in a total of 27 genetically unsolved patients in an external collagen VI-like dystrophy cohort, thus explaining approximately 25% of patients clinically suggestive of collagen VI dystrophy in whom prior genetic analysis is negative. Overall, this study represents the largest systematic application of transcriptome sequencing to rare disease diagnosis to date and highlights its utility for the detection and interpretation of variants missed by current standard diagnostic approaches.', u'/content/early/2016/09/08/074153', [], [u'The Broad Institute of MIT and Harvard;', u'National Institute of Neurological Disorders and Stroke, National Institutes of Health;', u'Institute for Neuroscience and Muscle Research, Childrens Hospital at Westmead;', u'Division of Pediatric Neurology, Department of Pediatrics, University of Florida College of Medicine;', u'Dubowitz Neuromuscular Centre, UCL Institute of Child Health;', u'Division of Neurology, Hospital for Sick Children;', u'Department of Neurology, University Hospitals Leuven and University of Leuven;', u'Department of Diagnostic Genomics, PathWest Laboratory Medicine;', u'Harry Perkins Institute of Medical Research, University of Western Australia;', u'The John Walton Muscular Dystrophy Research Centre, MRC Centre for Neuromuscular Diseases;', u'Division of Genetics and Genomics, Boston Childrens Hospital,;', u'Murdoch Childrens Research Institute, The Royal Childrens Hospital']]
[u'Assessing data quality in citizen science - preprint', ['Margaret Kosmala', 'Andrea Wiggins', 'Alexandra Swanson', 'Brooke Simmons'], u'September 8, 2016.', u'Ecological and environmental citizen science projects have enormous potential to advance science, influence policy, and guide resource management by producing datasets that are otherwise infeasible to generate. This potential can only be realized, though, if the datasets are of high quality. While scientists are often skeptical of the ability of unpaid volunteers to produce accurate datasets, a growing body of publications clearly shows that diverse types of citizen science projects can produce data with accuracy equal to or surpassing that of professionals. Successful projects rely on a suite of methods to boost data accuracy and account for bias, including iterative project development, volunteer training and testing, expert validation, replication across volunteers, and statistical modeling of systematic error. Each citizen science dataset should therefore be judged individually, according to project design and application, rather than assumed to be substandard simply because volunteers generated it.', u'/content/early/2016/09/08/074104', [], [u'Harvard University;', u'University of Maryland;', u'University of Oxford;', u'University of California, San Diego']]
[u'The impact of the newly licensed dengue vaccine in endemic countries', ['Maira Aguiar', 'Scott B. Halstead', 'Nico Stollenwerk'], u'September 8, 2016.', u'Caused by four antigenically related but distinct serotypes a tetravalent vaccine is needed to protect against the huge burden of dengue disease. Dengvaxia is a vaccine candidate now licensed in several countries for individuals 9-45 years of age living in endemic countries with least 70% of seroprevalence. Modelers from Sanofi Pasteur have predicted that this vaccine has the potential to reduce by about 50% the disease burden within 5 years when 20% of an endemic country population is vaccinated, thus achieving a World Health Organization dengue prevention goal. \n\nIn this paper, mathematical modeling is used to investigate the impact of the newly licensed dengue vaccine using different scenarios. Our results show that to achieve significant reduction in disease burden, the vaccination program is most effective if it includes only individuals that have been already exposed to at least one dengue virus. Immunological screening of the population prior to vaccination is advised and vaccination strategies must be planned based on epidemiological disease dynamics for each specific endemic region.\n\n*This paper was submitted to PLoS NTDs on April 10, 2016*', u'/content/early/2016/09/08/074062', [], [u'Lisbon University;', u'Department of Preventive Medicine and Biometrics']]
[u'Design of Vaccine Trials during Outbreaks with and without a Delayed Vaccination Comparator', ['Natalie Exner Dean', 'M Elizabeth Halloran', 'Ira M Longini'], u'September 8, 2016.', u'Conducting vaccine efficacy trials during outbreaks of emerging pathogens poses particular challenges.\nThe Ebola \xe7a suffit trial in Guinea used a novel ring vaccination cluster randomized design to target populations at highest risk of infection. Another key feature of the trial was the use of a delayed vaccination arm as a comparator, in which clusters were randomized to immediate vaccination or vaccination 21 days later. This approach, chosen to improve ethical acceptability of the trial, complicates the statistical analysis as participants in the comparison arm are eventually protected by vaccine. Furthermore, for infectious diseases, we observe time of illness onset and not time of infection, and we may not know the time required for the vaccinee to develop a protective immune response. As a result, including events observed shortly after vaccination may bias the per protocol estimate of vaccine efficacy. We provide a framework for approximating the bias and power of any given per protocol analysis period as functions of the background infection hazard rate, disease incubation period, and vaccine immune response. We use this framework to provide recommendations for designing standard vaccine efficacy trials and trials with a delayed vaccination comparator. Briefly, narrower analysis periods within the correct window can minimize or eliminate bias but may suffer from reduced power. Designs should be reasonably robust to misspecification of the incubation period and time to develop a vaccine immune response.', u'/content/early/2016/09/08/074088', [], [u'University of Florida;', u'Fred Hutchinson Cancer Research Center, University of Washington']]
[u'Insertion patterns of P{lacW} and P{EP} artificial transposons on the third chromosome of Drosophila melanogaster', ['Laura Ioana Popa', 'Attila Cristian Ratiu', 'Alexandru Al. Ecovoiu'], u'September 8, 2016.', u'Insertional mutagenesis experiments performed on Drosophila melanogaster model often relies on induced mobilization of artificial transposons derived from P mobile element. In an attempt to detect transposition preferences, we accomplished a pilot study concerning the insertional patterns of P{lacW} and P{EP} constructs in the third chromosome of D. melanogaster. Our inventory inquiry considered 2177 insertions of P{lacW} and 1646 insertions of P{EP} available in FB2016_02 release of FlyBase and revealed insertional hotspots and coldspots in 3L and 3R, but also a preference of both artificial transposons to insert in 3R. The general distribution of P{lacW} and P{EP} insertions appears to be similar but not identical, probably due to differences in size and molecular architecture of these transposons. Our results may have predictive value for experimental design of insertional mutagenesis screenings, but are also expected to contribute to a better understanding of P transposon biology.', u'/content/early/2016/09/08/074070', [u'Genetics'], [u'Department of Genetics, University of Bucharest']]
[u'Assessing the public health impact of tolerance-based therapies with mathematical models', ['Nathanael Hoze', 'Sebastian Bonhoeffer', 'Roland Regoes'], u'September 8, 2016.', u'Disease tolerance is a defense strategy against infections that aims at maintaining host health even at high pathogen replication or load. Tolerance mechanisms are currently intensively studied with the long-term goal of exploiting them therapeutically. Because tolerance-based treatment imposes less selective pressure on the pathogen it has been hypothesised to be \u201cevolution-proof\u201d. However, the primary public health goal is to reduce the incidence and mortality associated with a disease. From this perspective, tolerance-based treatment bears the risk of increasing the prevalence of the disease, which may lead to increased mortality. We assessed the promise of tolerance-based treatment strategies using mathematical models.  Conventional treatment was implemented as an increased recovery rate, while tolerance-based treatment was assumed to reduce the disease-related mortality of infected hosts without affecting recovery. We investigated the epidemic and endemic phases of two types of infections: acute and chronic. Additionally, we considered the effect of pathogen resistance against conventional treatment. We show that, for both   acute and chronic infections, tolerance-based therapy enlarges the population of infected hosts, which in turn increases the prevalence and incidence of the disease. For low coverage of tolerance-based treatment, chronic infections can cause even more deaths than without treatment. Overall, we found that conventional treatment always outperforms tolerance-based treatment, even when we allow the emergence of pathogen resistance. Our results cast serious doubts on the potential benefit of tolerance-based over conventional treatment. Any clinical application of tolerance-based treatment of infectious diseases has to consider the associated detrimental epidemiological feedback.', u'/content/early/2016/09/08/073700', [u'Epidemiology'], [u'ETH Zurich']]
[u'MTQuant: "Seeing" Beyond the Diffraction Limit in Fluorescence Images to Quantify Neuronal Microtubule Organization', ['Roshni Cooper', 'Shaul Yogev', 'Kang Shen', 'Mark Horowitz'], u'September 8, 2016.', u'Motivation: Microtubules (MTs) are polarized polymers that are critical for cell structure and axonal transport.\nThey form a bundle in neurons, but beyond that, their organization is relatively unstudied.\nResults: We present MTQuant, a method for quantifying MT organization using light microscopy, which\ndistills three parameters from MT images: the spacing of MT minus-ends, their average length, and the\naverage number of MTs in a cross-section of the bundle. This method allows for robust and rapid in vivo\nanalysis of MTs, rendering it more practical and more widely applicable than commonly-used electron\nmicroscopy reconstructions. MTQuant was successfully validated with three ground truth data sets and\napplied to over 3000 images of MTs in a C. elegans motor neuron.', u'/content/early/2016/09/08/074047', [u'Bioinformatics'], [u'Stanford University']]
[u'HiChIP: Efficient and sensitive analysis of protein-directed genome architecture', ['Maxwell R Mumbach', 'Adam J. Rubin', 'Ryan A. Flynn', 'Chao Dai', 'Paul A. Khavari', 'William J. Greenleaf', 'Howard Y. Chang'], u'September 8, 2016.', u'Genome conformation is central to gene control but challenging to interrogate. Here we present HiChIP, a protein-centric chromatin conformation method. HiChIP improves the yield of conformation-informative reads by over 10-fold and lowers input requirement over 100-fold relative to ChIA-PET. HiChIP of cohesin reveals multi-scale genome architecture with greater signal to background than in situ Hi-C. Thus, HiChIP adds to the toolbox of 3D genome structure and regulation for diverse biomedical applications.', u'/content/early/2016/09/08/073619', [u'Genomics'], [u'Stanford University']]
[u'Calculation of a distribution free estimate of effect size and confidence intervals using VBA/Excel', ['Joachim Goedhart'], u'September 8, 2016.', u"Reporting effect sizes aids the transparent presentation and independent interpretation of scientific data. However, calculation and reporting of effect sizes for data obtained in basic research is rare. A standardized effect size was reported by Norman Cliff, known as Cliff's delta. It has several advantageous features, as (i) it makes no assumption on the shape of the underlying distribution, (ii) it works well for small to moderate samples (n>10), (iii) it is easy to calculate, and (iv) its basis is readily understood by non statisticians. Here, a VBA macro, implemented in Excel, is presented. The macro takes two independent samples as input and calculates Cliff's delta with 95% confidence intervals. The macro will reduce the barrier for calculating the effect size and can be a valuable tool for research and teaching.", u'/content/early/2016/09/08/073999', [], [u'University of Amsterdam']]
[u'A self-initiated two-alternative forced choice paradigm for head-fixed mice', ['Fred Marbach', 'Anthony M Zador'], u'September 8, 2016.', u'Psychophysical tasks for non-human primates have been instrumental in studying circuits underlying perceptual decision-making. To obtain greater experimental flexibility, these tasks have subsequently been adapted for use in freely moving rodents. However, advances in functional imaging and genetic targeting of neuronal populations have made it critical to develop similar tasks for head-fixed mice. Although head-fixed mice have been trained in two-alternative forced choice tasks before, these tasks were not self-initiated, making it difficult to attribute error trials to perceptual or decision errors as opposed to mere lapses in task engagement. Here, we describe a paradigm for head-fixed mice with three lick spouts, analogous to the well-established 3-port paradigm for freely moving rodents. Mice readily learned to initiate trials on the center spout and performed around 200 self-initiated trials per session, reaching good psychometric performance within two weeks of training. We expect this paradigm will be useful to study the role of defined neural populations in sensory processing and decision-making.', u'/content/early/2016/09/08/073783', [u'Neuroscience'], [u'CSHL']]
[u'Secondary-structure prediction revisited: P\u03b2 and Pc represent structures of amyloids and aid elucidating phenomena in interspecies transmissions of prion.', ['YUZURU TAGUCHI', 'Noriyuki Nishida'], u'September 8, 2016.', u'Prion is a unique infectious agent which consists solely of abnormally-folded prion protein (PrPSc) but possesses virus-like features, e.g. existence of strain diversity, adaptation to new hosts and evolutionary changes. These biological phenomena were attributed to the structural properties of PrPSc due to lack of genetic material of prion. Therefore, regardless of  incompatibility with high-resolution structural analysis, many structural models of PrPSc have been hypothesized based on limited structural information and, recently models consisting solely of \u03b2-sheets and intervening loops/kinks have been suggested, i.e. parallel in-register \u03b2-sheet models and \u03b2-solenoid model. Given the relatively simple structural models of PrPSc, we utilized values of theoretical \u03b2-sheet or random-coil propensity (P\u03b2 or Pc, respectively) calculated by secondary structure prediction with a neural network to analyze interspecies transmissions of prion, because numerical conversion of the primary structures would enable quantitative comparison of PrP with distinct primary structures. Reviewing experiments in the literature, we ascertained biological relevance of P\u03b2 and Pc and demonstrated how those parameters could aid interpretation and explain phenomena in interspecies transmissions. Our approach can lead to development of a versatile tool for investigation of not only prion but also other amyloids.', u'/content/early/2016/09/08/073668', [u'Bioinformatics'], [u'Nagasaki University']]
[u'Overcoming confounding plate effects in differential expression analyses of single-cell RNA-seq data', ['Aaron TL Lun', 'John C Marioni'], u'September 8, 2016.', u'An increasing number of studies are using single-cell RNA-sequencing (scRNA-seq) to characterize the gene expression profiles of individual cells. One common analysis applied to scRNA-seq data involves detecting differentially expressed (DE) genes between cells in different biological groups. However, many experiments are designed such that the cells to be compared are processed in separate plates or chips, meaning that the groupings are confounded with systematic plate effects. This confounding aspect is frequently ignored in DE analyses of scRNA-seq data. In this article, we demonstrate that failing to consider plate effects in the statistical model results in loss of type I error control. A solution is proposed whereby counts are summed from all cells in each plate and the count sums for all plates are used in the DE analysis. This restores type I error control in the presence of plate effects without compromising detection power in simulated data. Summation is also robust to varying numbers and library sizes of cells on each plate. Similar results are observed in DE analyses of real data where the use of count sums instead of single-cell counts improves specificity and the ranking of relevant genes. This suggests that summation can assist in maintaining statistical rigour in DE analyses of scRNA-seq data with plate effects.', u'/content/early/2016/09/08/073973', [u'Bioinformatics'], [u'CRUK Cambridge Institute;', u'European Molecular Biology Laboratory - European Bioinformatics Institute']]
[u'A spatially resolved network spike in model neuronal cultures reveals nucleation centers, circular traveling waves and drifting spiral waves', ['Alexander Paraskevov', 'Dmitry Zendrikov'], u'September 8, 2016.', u'We show that in model neuronal cultures, where the probability of interneuronal connection formation decreases exponentially with increasing distance between the neurons, there exists a small number of spatial nucleation centers of a network spike, from where the synchronous spiking activity starts propagating in the network typically in the form of circular traveling waves. The number of nucleation centers, as well as their spatial location, is unique and unchanged for a given realization of neuronal network but is different for different networks. In contrast, if the probability of interneuronal connection formation is independent of the distance between neurons, then the nucleation centers do not arise and the synchronization of spiking activity during a network spike occurs spatially uniform throughout the network. Therefore one can conclude that spatial proximity of connections between neurons is important for the formation of nucleation centers. It is also shown that fluctuations of the spatial density of neurons at their random homogeneous distribution typical for the experiments in vitro do not determine the location of the nucleation centers. The simulation results are qualitatively consistent with the experimental observations.', u'/content/early/2016/09/08/073981', [u'Neuroscience'], [u'National Research Centre "Kurchatov Institute";', u'Moscow Institute of Physics and Technology (State University)']]
[u'13C metabolic flux ratio analysis by direct measurement of free metabolic intermediates in L. mexicana using gas chromatography-mass spectrometry', ['Milica Ng', 'Eleanor C. Saunders', 'Moshe Olshansky', 'Malcolm J. McConville', 'Vladimir Likic'], u'September 8, 2016.', u'Until recently, 13C-based flux analyses have almost exclusively relied on analysis of labelled amino acids in proteins. This approach is not directly applicable to Leishmania, as these parasites scavenge most of their amino acids from the media. Leishmania are also unusual in that they i) share little genomic similarity with other organisms ii) constitutively express their metabolic genes and iii) display minimal changes in the enzyme levels throughout their life cycle stages. The three factors have contributed to an early development of comprehensive and reproducible 13C-based metabolomics approaches in these parasites. The work presented here contributes to the creation of new 13C-based metabolic flux approaches based on the isotopologue analysis of free metabolite pools in Leishmania mexicana. Namely, a new approach is presented for simultaneous calculation of in vivo fractional fluxes (or flux ratios) into two or more metabolite nodes with carbon dioxide condensation, based on isotopologue analysis of free metabolite pools. This method is used to perform the first quantitative in vivo fractional flux calculation of central carbon metabolism in any human parasite.', u'/content/early/2016/09/08/073676', [u'Systems Biology'], [u'University of Melbourne, Parkville, Victoria 3010, Australia;', u'Walter and Eliza Hall Institute of Medical Research, 1 G Royal Parade, Parkville, Victoria 3052, Aus']]
