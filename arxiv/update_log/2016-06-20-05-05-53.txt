[u'Folding and Stabilization of Native-Sequence-Reversed Proteins', ['Yuanzhao Zhang', 'Jeffrey K Weber', 'Ruhong Zhou'], u'2016-06-16', u'Though the problem of sequence-reversed protein folding is largely\nunexplored, one might speculate that reversed native protein sequences should\nbe significantly more foldable than purely random heteropolymer sequences. In\nthis article, we investigate how the reverse-sequences of native proteins might\nfold by examining a series of small proteins of increasing structural\ncomplexity ({\\alpha}-helix, \\b{eta}-hairpin, {\\alpha}-helix bundle, and\n{\\alpha}/\\b{eta}-protein). Employing a tandem protein structure prediction\nalgorithmic and molecular dynamics simulation approach, we find that the\nability of reverse sequences to adopt native-like folds is strongly in\ninfluenced by protein size and the flexibility of the native hydrophobic core.\nFor \\b{eta}-hairpins with reverse-sequences that fail to fold, we employ a\nsimple mutational strategy for guiding stable hairpin formation that involves\nthe insertion of amino acids into the \\b{eta}-turn region. This systematic look\nat reverse sequence duality sheds new light on the problem of protein\nsequence-structure mapping and may serve to inspire new protein design and\nprotein structure prediction protocols.', u'http://arxiv.org/abs/1606.05373v1', ['Biomolecules'], []]
[u'Balancing New Against Old Information: The Role of Surprise', ['Mohammad Javad Faraji', 'Kerstin Preuschoff', 'Wulfram Gerstner'], u'2016-06-17', u'Surprise is a ubiquitous concept describing a wide range of phenomena from\nunexpected events to behavioral responses. We propose a measure of surprise, to\narrive at a new framework for surprise-driven learning. There are two\ncomponents to this framework: (i) a confidence-adjusted surprise measure to\ncapture environmental statistics as well as subjective beliefs, (ii) a\nsurprise-minimization learning rule, or SMiLe-rule, which dynamically adjusts\nthe balance between new and old information without making prior assumptions\nabout the temporal statistics in the environment. We apply our framework to a\ndynamic decision making task and a maze exploration task to demonstrate that it\nis suitable for learning in complex environments, even if the environment\nundergoes gradual or sudden changes. Our proposed surprise-modulated belief\nupdate algorithm provides a framework to study the behavior of humans and\nanimals encountering surprising events.', u'http://arxiv.org/abs/1606.05642v1', ['Neurons and Cognition'], []]
[u'Early Visual Concept Learning with Unsupervised Deep Learning', ['Irina Higgins', 'Loic Matthey', 'Xavier Glorot', 'Arka Pal', 'Benigno Uria', 'Charles Blundell', 'Shakir Mohamed', 'Alexander Lerchner'], u'2016-06-17', u'Automated discovery of early visual concepts from raw image data is a major\nopen challenge in AI research. Addressing this problem, we propose an\nunsupervised approach for learning disentangled representations of the\nunderlying factors of variation. We draw inspiration from neuroscience, and\nshow how this can be achieved in an unsupervised generative model by applying\nthe same learning pressures as have been suggested to act in the ventral visual\nstream in the brain. By enforcing redundancy reduction, encouraging statistical\nindependence, and exposure to data with transform continuities analogous to\nthose to which human infants are exposed, we obtain a variational autoencoder\n(VAE) framework capable of learning disentangled factors. Our approach makes\nfew assumptions and works well across a wide variety of datasets. Furthermore,\nour solution has useful emergent properties, such as zero-shot inference and an\nintuitive understanding of "objectness".', u'http://arxiv.org/abs/1606.05579v1', ['Neurons and Cognition'], []]
[u'A novel method linking neural connectivity to behavioral fluctuations:\n  Behavior-Regressed Connectivity', ['Antony D. Passaro', 'Jean M. Vettel', 'Jonathan McDaniel', 'Vernon Lawhern', 'Piotr J. Franaszczuk', 'Stephen M. Gordon'], u'2016-06-17', u'Background: During an experimental session, behavioral performance\nfluctuates, yet most neuroimaging analyses of functional connectivity derive a\nsingle connectivity pattern. These conventional connectivity approaches assume\nthat since the underlying behavior of the task remains constant, the\nconnectivity pattern is also constant.\n  New Method: We introduce a novel method, behavior-regressed connectivity\n(BRC), to directly examine behavioral fluctuations within an experimental\nsession and capture their relationship to changes in functional connectivity.\nThis method employs the weighted phase lag index (WPLI) applied to a window of\ntrials with a weighting function. Using two datasets, the BRC results are\ncompared to conventional connectivity results during two time windows: the one\nsecond before stimulus onset to identify predictive relationships, and the one\nsecond after onset to capture task-dependent relationships.\n  Results: In both tasks, we replicate the expected results for the\nconventional connectivity analysis, and extend our understanding of the\nbrain-behavior relationship using the BRC analysis, demonstrating\nsubject-specific connectivity patterns that correspond to both positive and\nnegative relationships with behavior.\n  Comparison with Existing Method(s): Conventional connectivity analyses assume\na consistent relationship between behaviors and functional connectivity, but\nthe BRC method examines performance variability within an experimental session\nto understand dynamic connectivity and transient behavior.\n  Conclusion: The BRC approach examines connectivity as it covaries with\nbehavior to complement the knowledge of underlying neural activity derived from\nconventional connectivity analyses. Within this framework, BRC may be\nimplemented for the purpose of understanding performance variability both\nwithin and between participants.', u'http://arxiv.org/abs/1606.05522v1', ['Neurons and Cognition'], []]
[u'Self-adaptation of Mutation Rates in Non-elitist Populations', ['Duc-Cuong Dang', 'Per Kristian Lehre'], u'2016-06-17', u'The runtime of evolutionary algorithms (EAs) depends critically on their\nparameter settings, which are often problem-specific. Automated schemes for\nparameter tuning have been developed to alleviate the high costs of manual\nparameter tuning. Experimental results indicate that self-adaptation, where\nparameter settings are encoded in the genomes of individuals, can be effective\nin continuous optimisation. However, results in discrete optimisation have been\nless conclusive. Furthermore, a rigorous runtime analysis that explains how\nself-adaptation can lead to asymptotic speedups has been missing. This paper\nprovides the first such analysis for discrete, population-based EAs. We apply\nlevel-based analysis to show how a self-adaptive EA is capable of fine-tuning\nits mutation rate, leading to exponential speedups over EAs using fixed\nmutation rates.', u'http://arxiv.org/abs/1606.05551v1', ['Populations and Evolution'], []]
[u'How does a protein reach its binding locus: sliding along DNA chain or\n  not?', ['Jingwei Li', 'Yunxin Zhang'], u'2016-06-17', u'In gene expression, various kinds of proteins need to bind to specific locus\nof DNA. It is still not clear how these proteins find their target locus. In\nthis study, the mean first-passage time (FPT) of protein binding to its target\nlocus on DNA chain is discussed by a chain-space coupled model. Our results\nshow that the 1-dimensional diffusion constant has a critical value, with which\nthe mean time spent by a protein to find its target locus is almost independent\nof the binding rate of protein to DNA chain and the detachment rate from DNA\nchain. Which implies that, the frequency of protein binding to DNA and the\nsliding time on DNA chain have little influence on the search efficiency, and\ntherefore whether or not the 1-dimensional sliding on DNA chain increases the\nsearch efficiency depends on the 1-dimensional diffusion constant of the\nprotein on DNA chain. This study also finds that only protein bindings to DNA\nloci which are close to the target locus help to increase the search\nefficiency, while bindings to those loci which are far from the target locus\nmight delay the target binding process. As expected, the mean FPT increases\nwith the distance between the initial position of protein in cell space and its\ntarget locus on DNA chain. The direct binding probability, which can be\nregarded as one index to describe if the 1-dimensional sliding along DNA chain\nis helpful to increase the search efficiency is calculated. Our results show\nthat the influence of 1-dimensional sliding along DNA chain on the search\nprocess depends on both diffusion constants of protein in cell space and on the\n1-dimensional DNA chain.', u'http://arxiv.org/abs/1606.05428v1', ['Subcellular Processes'], []]
