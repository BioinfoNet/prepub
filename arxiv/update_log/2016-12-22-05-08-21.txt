[u'Non-equilibrium chromosome looping via molecular slip-links', ['C. A. Brackley', 'J. Johnson', 'D. Michieletto', 'A. N. Morozov', 'M. Nicodemi', 'P. R. Cook', 'D. Marenduzzo'], u'2016-12-21', u'We propose a model for the formation of chromatin loops based on the diffusive sliding of a DNA-bound factor which can dimerise to form a molecular slip-link. Our slip-links mimic the behaviour of cohesin-like molecules, which, along with the CTCF protein, stabilize loops which organize the genome. By combining 3D Brownian dynamics simulations and 1D exactly solvable non-equilibrium models, we show that diffusive sliding is sufficient to account for the strong bias in favour of convergent CTCF-mediated chromosome loops observed experimentally. Importantly, our model does not require any underlying, and energetically costly, motor activity of cohesin. We also find that the diffusive motion of multiple slip-links along chromatin may be rectified by an intriguing ratchet effect that arises if slip-links bind to the chromatin at a preferred "loading site". This emergent collective behaviour is driven by a 1D osmotic pressure which is set up near the loading point, and favours the extrusion of loops which are much larger than the ones formed by single slip-links.', u'http://arxiv.org/abs/1612.07256v1', ['Biomolecules', 'Genomics'], []]
[u'The Global Dynamical Complexity of the Human Brain Network', ['Xerxes D. Arsiwalla', 'Paul Verschure'], u'2016-12-21', u"How much information do large brain networks integrate as a whole over the sum of their parts? Can the dynamical complexity of such networks be globally quantified in an information-theoretic way and be meaningfully coupled to brain function? Recently, measures of dynamical complexity such as integrated information have been proposed. However, problems related to the normalization and Bell number of partitions associated to these measures make these approaches computationally infeasible for large-scale brain networks. Our goal in this work is to address this problem. Our formulation of network integrated information is based on the Kullback-Leibler divergence between the multivariate distribution on the set of network states versus the corresponding factorized distribution over its parts. We find that implementing the maximum information partition optimizes computations. These methods are well-suited for large networks with linear stochastic dynamics. We compute the integrated information for both, the system's attractor states, as well as non-stationary dynamical states of the network. We then apply this formalism to brain networks to compute the integrated information for the human brain's connectome. Compared to a randomly re-wired network, we find that the specific topology of the brain generates greater information complexity.", u'http://arxiv.org/abs/1612.07106v1', ['Neurons and Cognition'], []]
[u'Similarities and differences between stimulus tuning in the inferotemporal visual cortex and convolutional networks', ['Bryan Tripp'], u'2016-12-21', u'Deep convolutional neural networks (CNNs) trained for object classification have a number of striking similarities with the primate ventral visual stream. In particular, activity in early, intermediate, and late layers is closely related to activity in V1, V4, and the inferotemporal cortex (IT). This study further compares activity in late layers of object-classification CNNs to activity patterns reported in the IT electrophysiology literature. There are a number of close similarities, including the distributions of population response sparseness across stimuli, and the distribution of size tuning bandwidth. Statisics of scale invariance, responses to clutter and occlusion, and orientation tuning are less similar. Statistics of object selectivity are quite different. These results agree with recent studies that highlight strong parallels between object-categorization CNNs and the ventral stream, and also highlight differences that could perhaps be reduced in future CNNs.', u'http://arxiv.org/abs/1612.06975v1', ['Neurons and Cognition'], []]
[u'Independent Noise Synchronizing Networks of Oscillator Networks', ['John Hongyu Meng', 'Hermann Riecke'], u'2016-12-20', u'Oscillators coupled in a network can synchronize with each other to yield a coherent population rhythm. If multiple such networks are coupled together, the question arises whether these rhythms will synchronize. We investigate the impact of noise on this synchronization for strong inhibitory pulse-coupling and find that increasing the noise can synchronize the population rhythms, even if the noisy inputs to different oscillators are completely uncorrelated. Reducing the system to a phenomenological iterated map we show that this synchronization of the rhythms arises from the noise-induced phase heterogeneity of the oscillators. The synchronization of population rhythms is expected to be particularly relevant for brain rhythms.', u'http://arxiv.org/abs/1612.06881v1', ['Neurons and Cognition'], []]
[u'Scale-invariance of ruggedness measures in fractal fitness landscapes', ['Hendrik Richter'], u'2016-12-21', u'The paper deals with using chaos to direct trajectories to targets and analyzes ruggedness and fractality of the resulting fitness landscapes. The targeting problem is formulated as a dynamic fitness landscape and four different chaotic maps generating such a landscape are studied. By using a computational approach, we analyze properties of the landscapes and quantify their fractal and rugged characteristics. In particular, it is shown that ruggedness measures such as correlation length and information content are scale-invariant and self-similar.', u'http://arxiv.org/abs/1612.07029v1', ['Populations and Evolution'], []]
[u'A Hidden Markov Movement Model for rapidly identifying behavioral states from animal tracks', ['Kim Whoriskey', 'Marie Auger-Methe', 'Christoffer Moesgaard Albertsen', 'Frederick G. Whoriskey', 'Thomas R. Binder', 'Charles C. Krueger', 'Joanna Mills Flemming'], u'2016-12-20', u'1. Electronic telemetry is frequently used to document animal movement through time. Methods that can identify underlying behaviors driving specific movement patterns can help us understand how and why animals use available space, thereby aiding conservation and management efforts. For aquatic animal tracking data with significant measurement error, a Bayesian state-space model called the first-Difference Correlated Random Walk with Switching (DCRWS) has often been used for this purpose. However, for aquatic animals, highly accurate tracking data of animal movement are now becoming more common. 2. We developed a new Hidden Markov Model (HMM) for identifying behavioral states from animal tracks with negligible error, which we called the Hidden Markov Movement Model (HMMM). We implemented as the basis for the HMMM the process equation of the DCRWS, but we used the method of maximum likelihood and the R package TMB for rapid model fitting. 3. We compared the HMMM to a modified version of the DCRWS for highly accurate tracks, the DCRWSnome, and to a common HMM for animal tracks fitted with the R package moveHMM. We show that the HMMM is both accurate and suitable for multiple species by fitting it to real tracks from a grey seal, lake trout, and blue shark, as well as to simulated data. 4. The HMMM is a fast and reliable tool for making meaningful inference from animal movement data that is ideally suited for ecologists who want to use the popular DCRWS implementation for highly accurate tracking data. It additionally provides a groundwork for development of more complex modelling of animal movement with TMB. To facilitate its uptake, we make it available through the R package swim.', u'http://arxiv.org/abs/1612.06921v1', ['Quantitative Methods'], []]
[u'Emergent structures and dynamics of cell colonies by contact inhibition of locomotion', ['Bart Smeets', 'Ricard Alert', 'Jiri Pesek', 'Ignacio Pagonabarraga', 'Herman Ramon', 'Romaric Vincent'], u'2016-12-20', u'Cells in tissues can organize into a broad spectrum of structures according to their function. Drastic changes of organization, such as epithelial-mesenchymal transitions or the formation of spheroidal aggregates, are often associated either to tissue morphogenesis or to cancer progression. Here, we study the organization of cell colonies by means of simulations of self-propelled particles with generic cell-like interactions. The interplay between cell softness, cell-cell adhesion, and contact inhibition of locomotion (CIL) yields structures and collective dynamics observed in several existing tissue phenotypes. These include regular distributions of cells, dynamic cell clusters, gel-like networks, collectively migrating monolayers, and 3D aggregates. We give analytical predictions for transitions between noncohesive, cohesive, and 3D cell arrangements. We explicitly show how CIL yields an effective repulsion that promotes cell dispersal, thereby hindering the formation of cohesive tissues. Yet, in continuous monolayers, CIL leads to collective cell motion, ensures tensile intercellular stresses, and opposes cell extrusion. Thus, our work highlights the prominent role of CIL in determining the emergent structures and dynamics of cell colonies.', u'http://arxiv.org/abs/1612.06901v1', ['Tissues and Organs'], []]
[u'Performance limits and trade-offs in entropy-driven chemical computers', ['Dominique Chu'], u'2016-12-21', u'The properties and fundamental limits of chemical computers have recently attracted significant interest as a model of computation, an unifying principle of cellular organisation and in the context of bio-engineering. As of yet, research in this topic is based on case-studies. There exists no generally accepted criterion to distinguish between chemical processes that compute and those that do not. Here, the concept of entropy driven computer (EDC) is proposed as a general model of chemical computation. It is found that entropy driven computation is subject to a trade-off between accuracy and entropy production, but unlike many biological systems, there are no trade-offs involving time. The latter only arise when it is taken into account that the observation of the state of the EDC is not energy neutral, but comes at a cost. The significance of this conclusion in relation to biological systems is discussed. Three examples of biological computers, including an implementation of a neural network as an EDC are given.', u'http://arxiv.org/abs/1612.07184v1', ['Molecular Networks'], []]
