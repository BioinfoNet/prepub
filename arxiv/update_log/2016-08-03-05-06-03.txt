[u'Multimodal Brain Visualization', ['Saad Nadeem', 'Arie Kaufman'], u'2016-08-02', u'Current connectivity diagrams of human brain image data are either overly\ncomplex or overly simplistic. In this work we introduce simple yet accurate\ninteractive visual representations of multiple brain image structures and the\nconnectivity among them. We map cortical surfaces extracted from human brain\nmagnetic resonance imaging (MRI) data onto 2D surfaces that preserve shape\n(angle), extent (area), and spatial (neighborhood) information for 2D (circular\ndisk) and 3D (spherical) mapping, split these surfaces into separate patches,\nand cluster functional and diffusion tractography MRI connections between pairs\nof these patches. The resulting visualizations are easier to compute on and\nmore visually intuitive to interact with than the original data, and facilitate\nsimultaneous exploration of multiple data sets, modalities, and statistical\nmaps.', u'http://arxiv.org/abs/1608.00936v1', ['Neurons and Cognition'], []]
[u'Split scores: a tool to quantify phylogenetic signal in genome-scale\n  data', ['Elizabeth S. Allman', 'Laura S. Kubatko', 'John A. Rhodes'], u'2016-08-02', u'Under the general Markov model of sequence evolution on a tree T , each\nbipartition of the taxa corresponds to a flattening -- a rearrangement of the\ndistribution of site pattern frequencies into a matrix. If the bipartition of\nthe taxa is induced by an edge e in the tree T, then this matrix flattening is\ngenerically of rank 4. For all other bipartitions of the taxa, the matrix\nflattening has rank greater than 4. Using this result, we introduce a split\nscore based on the singular value decomposition of a matrix to assess support\nfor splits in sequence data. Using simulation, we explore some of the\nproperties of the split score including its dependence on sequence length,\nbranch length, size of a split and its ability to detect true splits in the\nunderlying tree. Computation of the split score has been implemented in the\nsoftware package SplitSup. Using a sliding window analysis, split scores are\nused to detect changes in the evolutionary process in data from primates,\nmosquitoes, and viruses.', u'http://arxiv.org/abs/1608.00942v1', ['Populations and Evolution'], []]
[u'Evolutionary forces in language change', ['Christopher A. Ahern', 'Mitchell G. Newberry', 'Robin Clark', 'Joshua B. Plotkin'], u'2016-08-02', u"Languages and genes are both transmitted from generation to generation, with\nopportunity for differential reproduction and survivorship of forms. Here we\napply a rigorous inference framework, drawn from population genetics, to\ndistinguish between two broad mechanisms of language change: drift and\nselection. Drift is change that results from stochasticity in transmission and\nit may occur in the absence of any intrinsic difference between linguistic\nforms; whereas selection is truly an evolutionary force arising from intrinsic\ndifferences -- for example, when one form is preferred by members of the\npopulation. Using large corpora of parsed texts spanning the 12th century to\nthe 21st century, we analyze three examples of grammatical changes in English:\nthe regularization of past-tense verbs, the rise of the periphrastic `do', and\nsyntactic variation in verbal negation. We show that we can reject stochastic\ndrift in favor of a selective force driving some of these language changes, but\nnot others. The strength of drift depends on a word's frequency, and so drift\nprovides an alternative explanation for why some words are more prone to change\nthan others. Our results suggest an important role for stochasticity in\nlanguage change, and they provide a null model against which selective theories\nof language evolution must be compared.", u'http://arxiv.org/abs/1608.00938v1', ['Populations and Evolution'], []]
[u'Pareto-efficient biological pest control enable high efficacy at small\n  costs', ['Niklas L. P. Lundstrom', 'Hong Zhang', 'Ake Brannstrom'], u'2016-07-29', u'Biological pest control is increasingly used in agriculture as a an\nalternative to traditional chemical pest control. In many cases, this involves\na one-off or periodic release of entomopathogens. As the interaction between\nthe entomopathogen and the pest is complex and the production of\nentomopathogens potentially expensive, it is not surprising that both the\nefficacy and economic viability of biological pest control are debated. Here,\nwe investigate the performance of very simple control strategies. In\nparticular, we show how Pareto-efficient one-off or periodic release\nstrategies, which optimally trade off between efficacy and economic viability,\ncan be devised and used to enable high efficacy for small economic costs. We\ndemonstrate our method on a pest-pathogen-crop model with a tunable immigration\nrate of pests. By analyzing this model, we demonstrate that simple\nPareto-efficient one-off release strategies are typically efficacious and\nsimultaneously have average profits that are close to the theoretical maximum\nobtained by less efficacious and complicated profit-optimizing strategies. The\nonly exception occurs for high pest-immigration rates, in which case periodic\nrelease is preferable. The methods presented here can be extended to more\ncomplex scenarios and thus be used to identify promising biological pest\ncontrol strategies in many circumstances.', u'http://arxiv.org/abs/1608.00603v1', ['Populations and Evolution'], []]
[u'Configuring Random Graph Models with Fixed Degree Sequences', ['Bailey K. Fosdick', 'Daniel B. Larremore', 'Joel Nishimura', 'Johan Ugander'], u'2016-08-01', u'Random graph null models have found widespread application in diverse\nresearch communities analyzing network datasets. The most popular family of\nrandom graph null models, called configuration models, are defined as uniform\ndistributions over a space of graphs with a fixed degree sequence. Commonly,\nproperties of an empirical network are compared to properties of an ensemble of\ngraphs from a configuration model in order to quantify whether empirical\nnetwork properties are meaningful or whether they are instead a common\nconsequence of the particular degree sequence. In this work we study the subtle\nbut important decisions underlying the specification of a configuration model,\nand investigate the role these choices play in graph sampling procedures and a\nsuite of applications. We place particular emphasis on the importance of\nspecifying the appropriate graph labeling---stub-labeled or\nvertex-labeled---under which to consider a null model, a choice that closely\nconnects the study of random graphs to the study of random contingency tables.\nWe show that the choice of graph labeling is inconsequential for studies of\nsimple graphs, but can have a significant impact on analyses of multigraphs or\ngraphs with self-loops. The importance of these choices is demonstrated through\na series of three in-depth vignettes, analyzing three different network\ndatasets under many different configuration models and observing substantial\ndifferences in study conclusions under different models. We argue that in each\ncase, only one of the possible configuration models is appropriate. While our\nwork focuses on undirected static networks, it aims to guide the study of\ndirected networks, dynamic networks, and all other network contexts that are\nsuitably studied through the lens of random graph null models.', u'http://arxiv.org/abs/1608.00607v1', ['Quantitative Methods'], []]
[u'A Unified Paradigm of Organized Complexity and Semantic Information\n  Theory', ['Tatsuaki Okamoto'], u'2016-07-29', u'One of the most fundamental problems in science is to define {\\it\nquantitatively} the complexity of organized matters, i.e., {\\it organized\ncomplexity}. Although many measures have been proposed toward this aim in\nprevious decades, there is no agreed upon definition. This paper presents a new\nquantitative definition of organized complexity. This definition {\\it\nsimultaneously} captures the three major features of complexity: computational\n(similar to logical depth), descriptional (similar to the Kolmogorov complexity\nand effective complexity) and distributional (similar to statistical\ncomplexity). In addition, the proposed definition is computable and can measure\nboth probabilistic and deterministic forms of objects in a unified manner. The\nproposed definition is based on circuits rather than Turing machines and\n$\\epsilon$-machines. We give several criteria required for organized complexity\nmeasures and show that the proposed definition satisfies all of them for the\nfirst time. We then apply this quantitative definition to formulate a {\\it\nsemantic information theory}. We present the first formal definition of a {\\it\nsemantic information amount}, which is the core concept of the semantic\ninformation theory, that is based only on concretely defined notions. Previous\nsemantic information theories defined this amount under some a priori\ninformation which is not concretely specified. We then unveil several\nfundamental properties in the semantic information theory, e.g., a semantic\nsource coding theorem, semantic channel coding theorem, and effectiveness\ncoding theorem. Although the semantic information theory has a long history of\nresearch going back more than six decades, there has been no study on its\nrelation to organized complexity. This paper offers the first unified paradigm\nof organized complexity and semantic information theory.', u'http://arxiv.org/abs/1608.00941v1', ['Quantitative Methods'], []]
[u'Stem Cells: The Good, the Bad and the Ugly', ['Eric Werner'], u'2016-08-01', u'Cancer stem cells are controlled by developmental networks that are often\ntopologically indistinguishable from normal, healthy stem cells. The question\nis why cancer stem cells can be both phenotypically distinct and have\nmorphological effects so different from normal stem cells. The difference\nbetween cancer stem cells and normal stem cells lies not in differences their\nnetwork architecture, but rather in the spatial-temporal locality of their\nactivation in the genome and the resulting expression in the body. The\nmetastatic potential cancer stem cells is not based primarily on their network\ndivergence from normal stem cells, but on non-network based genetic changes\nthat enable the evolution of gene-based phenotypic properties of the cell that\npermit its escape and travel to other parts of the body. Stem cell network\ntheory allows the precise prediction of stem cell behavioral dynamics and a\nmathematical description of stem cell proliferation for both normal and cancer\nstem cells. It indicates that the best therapeutic approach is to tackle the\nhighest order stem cells first, otherwise spontaneous remission of so called\ncured cancers will always be a danger. Stem cell networks point to a pathway to\nnew methods to diagnose and cure not only stem cell cancers but cancers\ngenerally.', u'http://arxiv.org/abs/1608.00930v1', ['Tissues and Organs', 'Molecular Networks'], []]
[u"Genoautotomy (Genome 'Self-Injury') in Eukaryotic Cells: A Cellular\n  Defence Response to Genotoxic Stress", ['Gao-De Li'], u'2016-08-02', u"In this paper we propose that eukaryotic cells, under severe genotoxic\nstress, can commit genoautotomy (genome 'self-injury') that involves cutting\nand releasing single-strand DNA (ssDNA) fragments from double-stranded DNA and\nleaving ssDNA gaps in the genome. The ssDNA gaps could be easily and precisely\nrepaired later. The released ssDNA fragments may play some role in the\nregulation of cell cycle progression. Taken together, genoautotomy causes\nlimited nonlethal DNA damage, but prevents the whole genome from lethal damage,\nand thus should be deemed as a eukaryotic cellular defence response to\ngenotoxic stress.", u'http://arxiv.org/abs/1608.00903v1', ['Subcellular Processes'], []]
[u'Identification of repeats in DNA sequences using nucleotide distribution\n  uniformity', ['Changchuan Yin'], u'2016-07-31', u'Repetitive elements are important in genomic structures, functions and\nregulations, yet effective methods in precisely identifying repetitive elements\nin DNA sequences are not fully accessible, and the relationship between\nrepetitive elements and periodicities of genomes is not clearly understood. We\npresent an $\\textit{ab initio}$ method to quantitatively detect repetitive\nelements and infer the consensus repeat pattern in repetitive elements. The\nmethod uses the measure of the distribution uniformity of nucleotides at\nperiodic positions in DNA sequences or genomes. It can identify periodicities,\nconsensus repeat patterns, copy numbers and perfect levels of repetitive\nelements. The results of using the method on different DNA sequences and\ngenomes demonstrate efficacy and accuracy in identifying repeat patterns and\nperiodicities. The complexity of the method is linear with respect to the\nlengths of the analyzed sequences.', u'http://arxiv.org/abs/1608.00567v1', ['Genomics'], []]
